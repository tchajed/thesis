\section{Verifying the Dafny implementation}%
\label{sec:design}

We follow the standard approach for verifying software in Dafny: each
file-system operation is implemented as a method on a class and its
specification is given using pre- and post-conditions. In discussing the
soundness theorem we considered the Dafny proof as one theorem. In this
section we walk through the structure of the Dafny proof and explain some interesting
challenges we addressed along the way.

% The proof is given by annotating the code with proof steps, which include
% updates to ghost state, assertions to assist the automated verification, and
% calls to lemmas.

\sys is implemented and verified in several layers of abstraction. Each layer is
implemented as a class that wraps the lower layer as a field; the highest layer
exports the methods in the NFS API while the lowest is the transaction system.
The transaction system is an assumed interface in Dafny and implemented in Go
outside of Dafny. We implement the NFS wire protocol in unverified code that
imports the filesystem class, compiled from Dafny, and calls its methods wrapped
in a transaction.

% The approach we follow is inspired by xv6. We borrow some tricks from FSCQ and
% Yggdrasil to accomodate verification (especially using more layers than the xv6
% C implementation). We also needed to adapt the proof a bit so that rather than
% using separation logic we encode disjointness in an SMT-friendly way. The
% approach we take is standard and the same as used in Yggdrasil (see how layer 3
% works).

\begin{figure}
\begin{tabular}{ll}
  \toprule
  \textbf{Layer} & \textbf{functionality} \\
  \midrule
  dir & Directories and top-level NFS API. \\
  typed & Inode allocation. \\
  byte & Implement byte-level operations using blocks. \\
  block & Gather blocks for each file into a single sequence. \\
  indirect & Triple-indirect blocks organized in a tree. \\
  inode & In-memory, high-level inodes; block allocation. \\
  txn & Assumed interface to external transaction system. \\
  \bottomrule
\end{tabular}
\caption{Layers in the Dafny implementation and proof of the file-system
operations.}
\label{fig:dafny-layers}
\end{figure}

Although the file system is implemented with six layers (see
\autoref{fig:dafny-layers}), there are three difficult pieces of
functionality: organizing data blocks into metadata and data (the
indirect and block layers), translating byte-level operations into
block operations (the byte and typed layers), and implementing
directories as special files that the file system itself reads and
writes (the dir layer). The modularity was essential to complete the proof in
manageable chunks (to avoid overwhelming the developer and prover), and it would
have been natural even without verification.

\subsection{Achieving good performance}

An important aspect of the Dafny proof was to write code in a way that produces
high-performance Go code. For example, it is possible to write in a highly
functional style with immutable data structures rather than mutable objects;
this simplifies proofs
but generally results in lower performance. Compiling to Go exacerbates this
problem because Dafny's built-in immutable collections (sequences and maps) are
extremely inefficient in Go due to an impedance mismatch between Dafny and Go
semantics. Compared to Dafny's C\# backend, the generated Go code has much
additional pointer indirection and defensive copying.

Dafny's default integer type \cc{int} is unbounded and compiled to big integer
operations for soundness, in all target languages. We used Dafny's
\cc{nativeType} support to instead define a type of 64-bit integers (that
is, natural numbers less than $2^{64}$) and compile this to Go's \cc{uint64}.
This requires overflow reasoning whenever arithmetic is involved, but the
automation makes this palatable in the proof and the performance gain is quite
significant.

To avoid using Dafny's built-in collections we use an axiomatized interface to
Go byte slices (\cc{[]byte} in Go) whenever raw data is required, including file
data and paths, and then modify these slices in-place. It was possible to
axiomatize this API without any changes to Dafny; we use a standard Dafny
feature of \cc{:extern} classes to specify a Dafny class \cc{Bytes} in terms of
ghost state of type \cc{seq<byte>} but then implement it as in Go as a thin
wrapper around the native \cc{[]byte} type. Since this API is trusted we
carefully wrote tests. To catch off-by-one errors in the specification, we wrote
concrete tests like \verb![]byte{1,2,3}[2]! and ran them in both Go and
(equivalent) Dafny (this test should return 3 because both languages are
zero-indexed).

We implement the file system fairly efficiently, taking advantage of Dafny's
support for imperative code. The on-disk data structures---inodes, indirect
blocks, and directories---are represented in memory in their serialized form and
modified by updating this representation directly, avoiding copies to move
between representations. At first these were written with slower purely
functional code, which we were able to easily migrate to imperative code that
used the functional code as a specification rather than directly executing it.

\subsection{Challenges in the proof}

The design of \sys is broadly similar to the operating system in xv6~\cite{xv6},
as well as Yggdrasil~\cite{sigurbjarnarson:yggdrasil}, a verified sequential
file system. We encountered some unique challenges due to a more complete
implementation. In this section we highlight two particular features: the
support for large files with triply-indirect blocks in the indirect layer, and
freeing space from deleted files.

\subsubsection{Large files}
\label{sec:dafny:indirect}

The indirect and block layers together implement an abstraction of
files as a sequence of blocks, using some blocks in the transaction
system as indirect blocks that contain pointers to other blocks.  Most
of the code implementing indirect blocks is implemented recursively
using an approach borrowed from DFSCQ~\cite{akonradi-meng}.
In practice we configure the system with several direct and (single)
indirect blocks in an inode to make small files more efficient, plus a
triple-indirect block that allows files to grow to 512GB.

%% Using only a single level of
%% indirection would be convenient for verification, but it would limit the size of
%% files to 28MB. Instead, we use multiple levels of indirection. Indirect blocks
%% have a natural recursive structure, where a $k$-indirect block holds pointers to
%% $(k-1)$-indirect blocks, down to $k=0$ for the data blocks.

%% Files at the block layer are always of the maximum size, to avoid
%% reasoning about sizes until the higher layers. To efficiently
%% represent such large files, the zero block number is treated specially
%% as encoding a zero block, including for indirect blocks; an idea we
%% borrowed from DFSCQ~\cite{akonradi-meng}. Because this works
%% recursively, the single zero for the root of the triple-indirect block
%% address efficiently stores the many GBs of zeros in a typical small
%% file.

%% The representation of file data using zero addresses and
%% recursive indirect block implementation were directly inspired by the
%% DFSCQ indirect-block~\cite{akonradi-meng}.

Indirect blocks pose a challenge for verification due to the classic problem of
\emph{aliasing}. The proof must show that modifying a data block or indirect
block has no effect on other files. In the DFSCQ proof, the invariant
captures the non-aliasing between files using separation logic, which makes
disjointness easy to express. In Dafny we have no such logical
technique, so we instead use a standard SMT-friendly trick for the invariant: in
addition to the physical mapping that tracks how to dereference a block address,
the indirect layer proof tracks a ghost \emph{reverse} mapping that tracks where
each in-use block number is stored. The invariant states that the forward and reverse
mappings are inverses of each other, which implies that modifying an address
only affects its owner and nothing else.

%% To encode the reverse mapping, we need a data type to represent the location of
%% a block within an inode. With indirect blocks, the metadata blocks themselves
%% also need to be considered locations, since the invariant must also rule out
%% metadata aliasing with data or other metadata. We encode locations with a
%% position datatype that encodes an inode, an indirection level, and an offset for
%% the blocks at that indirection level. If we imagine that an inode's block
%% pointers are organized in a tree, the roots are stored directly in the inode
%% while the leaves are direct blocks. An indirection level which is higher than
%% the leaf level describes a metadata block.

%% The indirect block proof is split into the indirect and blocks layers. In the
%% indirect layer, the abstract state maps positions (including the inode number)
%% to data, and off to the side tracks the size and attributes of each inode. The
%% block layer changes this representation to a flat sequence of blocks by mapping
%% each leaf position to its linear index within the inode. Separating these two
%% made it easier to work on the indirect layer while giving the upper layers the
%% much more natural abstraction of a file as a sequence of blocks.

\subsubsection{Freeing space}
\label{sec:dafny:freeing}

Freeing space becomes surprisingly tricky with large files. The problem is that
it can take some time to track down all the block numbers that need to be freed,
and this can result in a large transaction if the file system is big enough.
\sys handles freeing by removing a file from its inode and marking it free in
one transaction, and separately reclaiming all the space it took by deallocating
all of its blocks.

The implementation thus implements removal as a combination of two transactions,
one which implements the logical operation but leaks space, and an operation
\cc{ZeroFreeSpace(ino)} which frees and zeros the unused space in an inode that
we prove has no effect on the file-system state. Because this operation is a
logical no-op, it is safe to call it at any time. In practice the implementation
is careful to call it after any operation that leaves unused blocks, in
particular \cc{SETATTR}, which can shrink a file by reducing its size, and
\cc{REMOVE}, which deletes a file. Furthermore since \cc{ZeroFreeSpace} doesn't
affect the user-visible data, it is free to return early to avoid overflowing a
transaction, which is limited to 511 blocks due to the design of GoJournal.

There is one case where freeing blocks is important for correctness and not just to reclaim space. Growing a file is supposed to logically fill the new space with
zeros. If the file had old data in that space, it would not be zero but some
previously written and deleted data, which both violates the specification and
is a potential security risk. The way we handle this with background freeing is
with validation: the \cc{SETATTR} operation when it grows a file checks if the
free space is already zero first, and fails with a special error code. The
unverified code interprets this as a signal to immediately call
\cc{ZeroFreeSpace} and try the operation again. The same support also handles
holes created by writing past the end of a file, which are similarly supposed to
be zero.

The freeing implementation is an interesting example of using validation in
verification. The specification for much of the freeing code is loose, allowing
any data to be written to the free space. We only needed a strong specification
for the code that checks if the zeroing is done; the rest of the code needs to
be correct for this check to ever succeed, but we aren't required to prove it.

% \subsection{Random notes on development process}
%
% \begin{itemize}
%   \item Used inefficient functional Dafny code at first, then slowly migrated to
%         in-memory data structures and improved performance.
%   \item Hard to debug and fix timeouts. Profiling verification performance is
%         hard.
%   \item Profiling Go code is great as usual. The generated code looks strange,
%         but I think after code generation it's pretty ordinary (the weird things
%         are mostly bad variable names, lot of unused assignments, and anonymous
%         functions that are immediately called).
%   \item Used some unit tests, but very few and only at the top level. Mainly
%         debugged Go compilation issues and cases where errors were
%         unintentionally being returned.
%   \item Trusted code isn't easy, had bugs in it before testing it thoroughly.
%         Also violated preconditions in top-level specs, triggering memory-safety
%         bugs.
% \end{itemize}
