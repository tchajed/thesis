\section{Primer on Iris and separation logic}

A program logic is a formal system for specifying and reasoning about programs.
One of the simplest program logics is Hoare logic, still the basis for much
sequential reasoning today. The judgments of Hoare logic consist of
specifications of the form $\hoare{P}{e}{Q}$, which is interpreted as meaning
``if $e$ is run in a state where $P$ holds and it terminates, then the final
state will satisfy $Q$''. The logic has various rules for proving and combining
these specifications.

\subsection{Separation logic}

Separation logic is an extension of Hoare logic that has proven profitable for
reasoning about heap-manipulating programs with pointers and concurrency
(surprisingly, the same techniques help solve both problems). A good
introduction to the basic ideas of separation logic is found in O'Hearn's
``Separation Logic'' article~\cite{ohearn:seplogic}. This section gives a more
terse overview, especially to introduce the relevant notation.

Separation logic introduces some notation for the logical assertions that
describe the heap. The core assertion to talk about pointers is $p \mapsto v$,
pronounced ``$p$ points to $v$'',
which says that the pointer $p$ when dereferenced has value $v$. The new logical
connective of separation logic is
$P \sep Q$, pronounced ``$P$ and separately $Q$'', which says that the heap can
be divided into two disjoint pieces, one satisfying $P$ and the other satisfying
$Q$. Entailment between propositions is written $P \proves Q$, read as ``$P$
entails $Q$'' or ``$P$ proves $Q$'', which says that in any heap where $P$
holds, $Q$ must also hold.

When working in separation logic, specifications like $\hoare{P}{e}{Q}$ are
generally stated in a ``small footprint'' style where $P$ mentions only the
state $e$ relies on for its execution. This intuition is backed by the
celebrated frame rule, which says that if $\hoare{P}{e}{Q}$ holds, any disjoint
state is unaffected, namely $\hoare{P \sep F}{e}{Q \sep F}$.

Instead of working with Hoare triples, it is convenient to instead define
specifications in a different style of \emph{weakest preconditions} (WPs). We will use
$\wpre{e}{Q}$ to denote the weakest precondition of $e$ with postcondition $Q$;
if $e$ is run in a state satisfying $\wpre{e}{Q}$ and terminates, the final
state will satisfy $Q$. Note that the $\wprew$ is a \emph{predicate over
states}, not an assertion like a Hoare triple. To build intuition, the statement
$P \proves \wpre{e}{Q}$ is equivalent to $\hoare{P}{e}{Q}$. An excellent
explanation of weakest preconditions vs Hoare triples can be found in
``Separation logic for sequential programs''~\cite{chargueraud:seq-seplogic}.

The term ``weakest precondition'' is because $\wpre{e}{Q}$ is supposed to be the
\emph{weakest} predicate that implies $Q$ holds after $e$'s execution, in the
sense that any other precondition would imply $\wpre{e}{Q}$, but our work does not
emphasize this aspect of weakest preconditions. Furthermore the literature will
sometimes distinguish between weakest liberal preconditions that only guarantee
$Q$ if $e$ terminates and reserve the term weakest preconditions for a predicate
that also guarantees termination. This thesis uses the term weakest precondition for the
``liberal'' version (also called \emph{partial correctness} as opposed to
\emph{total correctness}), because proving termination in the presence of
concurrency is quite challenging.

As an example of weakest precondition reasoning, the frame rule becomes
\ruleref{wp-frame} in terms of WPs. Reading this rule forwards, if in a proof
the assumptions include $F$
and separately $\wpre{e}{Q}$, then we can move $F$ to the postcondition because
separation logic guarantees the proof of the WP does not affect or invalidate
the resources in the frame $F$.

\begin{figure}
\begin{mathpar}
\inferH{wp-frame}%
{}%
{F * \wpre{e}{Q} \proves \wpre{e}{F * Q}}

\inferH{wp-mono}%
{P \proves P' \and \forall v. ([v/x] Q' \proves [v/x] Q) \and \hoare{P'}{e}{Q'}}%
{\hoare{P}{e}{Q}}

\inferH{wp-seq}%
{\hoare{P}{e_1}{Q} \and \hoare{Q}{e_2}{R}}%
{\hoare{P}{e_1;\, e_2}{R}}

\inferH{wp-load}%
{}{\hoare{p \mapsto v}{\load{p}}{\Ret{v} p \mapsto v}}

\inferH{wp-store}%
{}{\hoare{p \mapsto v}{\store{p}{v'}}{p \mapsto v'}}

\end{mathpar}
\caption{Selection of proof rules for sequential separation logic.}
\label{fig:wp-rules}
\end{figure}

\subsection{Ghost state and concurrency in Iris}
\label{sec:perennial:concurrency}

Iris generalizes separation logic to also reason about concurrency. A full
explanation of the Iris logic is out-of-scope for the thesis; ``Iris from the
ground up''~\cite{jung:iris-jfp} is a comprehensive introduction while the
original ``Iris 1.0'' paper~\cite{jung:iris-1} is a shorter introduction for a
reader already familiar with separation logic. Two features of Iris are most
relevant since they are used in the GoTxn proof: ghost state and invariants.

Ghost state is a technique for reasoning about a program by augmenting its
physical state (local variables and the heap) with some additional \emph{ghost
state} which is maintained only for the sake of the proof and has no effect on
the program's execution (hence the term ``ghost''). It is easier to understand
ghost state via its API in Dafny as a programming-language feature, so let
us first see how they help there and then return to Iris.

In Dafny, a variable can be marked \cc{ghost}. Ghost variables can be written
and read in the proof, but Dafny enforces that the ghost variables' values never
influences execution; they can only be used to inform uses of lemmas,
assertions, and other proof annotations. Then at run time ghost variables and all
uses of them are \emph{erased} before running the program. Why would adding a
ghost variable to a program help with its proof? The simplest examples are code
where a ghost variable holds the old value of some variable, say prior to a
loop; this lets the proof refer to the old value while clarifying that the
regular execution does not need it.\footnote{For a concrete example, see the
bubble sort example in
\url{https://www.doc.ic.ac.uk/~scd/Dafny_Material/Lectures.pdf}.}

Ghost variables can also be used to give abstract specifications to a piece of
code. For example, consider a ``statistics database'' that maintains the running
mean of a sequence of numbers. The code might only track the number of elements and
their sum, but the behavior of the library is easiest to state in terms of the list of all
numbers added. Thus in Dafny such a library can use a ghost variable to track
the full database, relate this ghost variable to the physical variables
of the code, and then prove that the code returns the correct running mean in
terms of the ghost state.

One intuition for the technique of ghost variables is that it augments the
execution of the program with additional information, which is used only for the proof
and thus not tracked at run time. For every actual execution, there is a
corresponding execution where the ghost variables are maintained and updated.
The proof is carried out on this augmented execution,
but the proofs apply to the normal execution because by design they have the
same behavior. Verifying the program with ghost
variables is easier because the ghost variables can track important
information about the history of the program, such as in the example above of
the pre-loop values of the local variables.

In Iris, the proof is a separate entity from the code. The program logic still
has a way to use ghost variables, with proof rules that construct and update a
ghost variable, applied at the appropriate points in the proof rather than added
to the code. The high-level idea for why this works --- that there is an
augmented execution with the ghost variables ---
remains the same. In fact in Iris it is more obvious
that the ghost variables do not affect program execution, since their creation
and updates only appear in the proof.

So far, we've explained ghost state in terms of ghost variables, with the familiar
API where they can be read and written. Iris ghost state is a bit more
sophisticated in order to support concurrency reasoning. First, Iris has
separation logic assertions for \emph{ownership} of ghost state, which can be
split and divided among threads. Second, ghost state can have restrictions on
how it may be updated.

\newcommand{\dashedbox}[1]{\boxedassert[densely dashed]{#1}[]}
\newcommand{\ghostvar}[2][]{\dashedbox{\gamma \mapsto_{#1} #2}}

A simple example to illustrate both principles is Iris's fractional ghost
variables. The assertion $\ghostvar[q]{v}$ says that $\gamma$ has value
$v$ (of any fixed type) and asserts ownership over a (positive) fraction $q$ of
it --- any fraction $q < 1$ represents read-only access to the ghost variable,
while full ownership $q = 1$ allows writing as well.
Complete ownership $\ghostvar[1]{v}$ is common enough that it is often
abbreviated to
$\ghostvar{v}$, with no fraction. The dashed box around this assertion emphasizes that this
assertion is about ghost state and not about the heap, as in the points-to
assertion $p \mapsto v$.  There are several rules for manipulating and
using this fractional ghost state:

\begin{mathpar}
  \inferH{frac-alloc}{}%
  {\proves \upd \exists \gamma.\, \ghostvar[1]{v}}

  \inferH{frac-update}{}%
  {\ghostvar[1]{v} \proves \upd \ghostvar[1]{v'}}

  \inferH{frac-split}{}%
  {\ghostvar[q_1 + q_2]{v} \provesIff \ghostvar[q_1]{v} \sep \ghostvar[q_2]{v}}

  \inferH{frac-agree}{}%
  {\ghostvar[q_1]{v_1} \sep \ghostvar[q_2]{v_2} \proves v_1 = v_2}

  \inferH{upd-fire}%
  {P \proves \wpre{e}{Q}}%
  {\upd P \proves \wpre{e}{Q}}
\end{mathpar}

The new notation $\upd P$ is an Iris \emph{update modality}. The assertion
$\upd P$ expresses ownership of resources which could be used to become $P$ with
some update to ghost state. As an example of proving an update modality,
\ruleref{frac-alloc} shows that starting with no assertions it is possible to
allocate a new ghost variable $\gamma$ with value $v$ and complete ownership
over it; this is analogous to how the Hoare triple for allocation has no
precondition. The formal rule that allows the user to get access to $P$ is
\ruleref{upd-fire}. It corresponds to advancing the proof of $\wpre{e}{Q}$ by
changing whatever ghost state is needed to turn $\upd P$ into $P$. As long as
the user of the logic is proving a weakest precondition as the goal, they can
apply this rule to ``eliminate'' an update modality.

Fractional ghost state can be updated after creation with \ruleref{frac-update}.
The update requires full ownership. Fractional ghost variables can instead be
split into smaller pieces with \ruleref{frac-split}; these pieces can no longer
be updated (since this would invalidate the rest of the assertions), but two
assertions for the same ghost variable must be for equal values since the
underlying variable has only one value.

This thesis describes a few constructions for ghost state to carry out parts of
the proof, including fractional ghost state described above. In reality all
ghost state in Iris is defined using a single, general mechanism. Ghost state
can come from any instance of an algebraic structure $M$ called
a ``resource algebra'', where ownership really means
ownership of an element $a \in M$. This thesis does not explain the details of
how ghost state is constructed using resource algebras --- see
``Iris from the ground up''~\cite{jung:iris-jfp}. For the ghost
state in this thesis, we will only give the API, in terms of resources and
rules that allow updating those resources. The Iris logic ensures that the
updates are ``sound'', enforcing a global property that updates to a resource in
one part of the proof never invalidate resources owned by concurrent threads at
the same time.

A fundamental reasoning principle for concurrency is the notion of an
\emph{invariant}. Threads will eventually need to share state, and invariants
are the main way to reason about how threads coordinate on that shared state.
Invariants in Iris are another resource: we write $\knowInv{}{I}$ for the
assertion that says $I$ is an invariant. Once this invariant is established, the
proof rules in Iris guarantee that $I$ holds at all steps of the program. A
thread that has $\knowInv{}{I}$ in its precondition can make use of the
invariant by ``opening'' it, but only for a single program step; it must be
returned afterward to guarantee the invariant holds for other threads. Finally,
invariants are freely \emph{duplicable} --- that is,
$\knowInv{}{I} \proves \knowInv{}{I} \sep \knowInv{}{I}$ --- reflecting that
knowledge of an invariant, once it is established, is an assertion that all
threads agree on which cannot be invalidated.

% \tej{Look at Perennial 1.0 paper and Later Credits paper for some inspiration on
% introducing Iris}
