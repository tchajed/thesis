One crucial service in an operating system is its \emph{file system}, the piece
of software that takes a disk (which simply stores a long sequence of bytes) and
makes it more useful by giving applications the abstraction of files and directories. The file
system is important because applications rely on it to store data, and to
persist that data even if the computer shuts down (perhaps unexpectedly, say due
to a power failure) and reboots. Due to their importance to nearly all applications, many
file systems have internally complicated implementations, with optimizations and
concurrency for high performance. However, due to this complexity, file systems
sometimes have bugs, especially subtle bugs that only manifest if the system
crashes at an inopportune time or if concurrent operations interleave in just
the wrong way. These bugs can result in the file system misbehaving, for example
losing files when the file system's internals are corrupted.

A file system's developers generally use testing to identify and fix bugs in the
implementation. Unfortunately, testing is fundamentally difficult due to the
combination of a concurrent implementation and the requirement that the file
system be correct even when the computer crashes. Both of these facets of a file
system mean even a handful of operations can have a large number of possible
executions, making it difficult to test all of them and gain high confidence in the
implementation.

This thesis takes an alternate approach to testing to obtain a correct file
system: we formally verify a new file-system implementation against a high-level
specification of the file system's behavior. The high-level approach of this
thesis is to \emph{implement} a file system, define a mathematical
\emph{specification} of what the file system is supposed to do, and then
\emph{prove} that the implementation always meets the specification regardless
of how the program executes and even under crashes. To increase confidence in
the proof, we carry it out with a computer; such a machine-checked proof
formalizes the proof as code that is automatically checked
for correctness against the specification and implementation.

The thesis's contributions address two main challenges in verifying a file system. The
first challenge is reasoning about the combination of crash safety and
concurrency at all, for which we build a framework that applies to efficient
code (written in Go) and can handle the sorts of reasoning in the file system.
The second challenge is the complexity of the implementation, which we address
with a novel, verification-friendly file-system design that allows us to reason
about each operation as if it were atomic, resulting in much simpler sequential reasoning.

More concretely the verified
artifact from this thesis is \textbf{DaisyNFS}, which implements the Network
File System (NFS) protocol on top of a disk with block-based access. NFS is a
widely-used protocol for exporting a file system across a network. We chose to
implement NFS since the behavior of an NFS server is relatively well-specified
by the RFC 1813 standard, compared to the requirements on a Linux file system,
for example. The specification for our file system stipulates that each
operation is implemented atomically (with respect to both other threads and on
crash), and behaves according to a formal model of the NFS specification as laid
out in prose in RFC 1813.

DaisyNFS has a novel file-system design where all disk access goes through a
\emph{transaction system} we call GoTxn. The advantage of this design is that the
transaction system makes calling code appear to run in sequential transactions,
isolating crash safety and concurrency concerns to the transaction system
implementation. As a side effect of having simpler sequential reasoning, we were
able to focus our effort on writing file-system features and getting good
performance. While other file systems (including the most common Linux file
system, ext4, and the Windows NTFS file system) also use transactions, DaisyNFS
uses them in a principled way such that every file-system operation is
automatically made atomic. In many other file systems there remains state
outside the transaction system, resulting in a subtle implementation where the
developer must still coordinate between the updates within a transaction and the
updates outside, for example by adding additional locking.

A key technical contribution that allows us to verify this file-system design is
a formal specification of how the transaction system guarantees atomicity. Our
formal specification is backed by a machine-checked proof against the GoTxn
implementation, giving confidence that this specification is actually achieved.
A challenge in this specification is formalizing under what conditions the
transaction system is able to guarantee atomicity --- for example, transactions
that read or write global state outside the transaction system cannot be made atomic.

The transaction system has a high-performance implementation since it is the
bottleneck for the file-system's performance, resulting in tricky concurrency
and crash safety patterns. This thesis develops new foundations that make this
reasoning possible for efficient implementations: \textbf{Perennial} is a new program logic for
reasoning about the combination of concurrency and crash safety, and
\textbf{Goose} is a tool for reasoning about a Go implementation using Perennial.

This thesis aims for the goal of making verifying a concurrent file system
feasible and scalable in terms of features and performance. In particular this thesis
makes the following contributions:
\begin{itemize}
  \item Perennial 2.0: a verification framework for reasoning about crash
  safety and concurrency. A new primitive for transferring ownership of durable
  state helped us reason about complex interactions in the transaction system's
  implementation.
  \item Goose: a system for reasoning about Go using Perennial. We needed a
  new and flexible system to support our custom verification infrastructure, and
  Go was a good platform for writing code and improving its performance.
  \item GoTxn: a verified transaction system with a proof showing transactions have the
    illusion of sequential, atomic execution, with respect to both crashes and other
    threads. The proof uses Perennial to establish a theorem about any calling code.
  \item DaisyNFS: a file system that takes advantage of the transaction system's
    correctness theorem to reason about each transaction in Dafny, a
    sequential verification language. A key contribution is a linking theorem
    that shows how the Dafny and Perennial proofs can be composed.
\end{itemize}

DaisyNFS implements the NFSv3 protocol, a standard protocol for exposing
a file system over the network. We use DaisyNFS by mounting it with the
Linux NFS client and then interacting with the mounted file system using
the standard system-call API.\@ A performance evaluation of DaisyNFS shows
that it is competitive with the Linux kernel NFS server exporting an
ext4 file system.

\section{State of the art}

Production file systems are generally validated by testing. While testing is
indispensible for development, the nature of a file system makes it difficult to
catch all bugs with only testing. The fundamental difficulty is a high degree of
non-determinism from two sources: crashes in the middle of execution, and
concurrency in the implementation that is needed for good performance.

The importance of file-system correctness has been recognized by the academic
community, thus there are many approaches for increasing confidence with
improved testing. One line of work has explored systematically testing crashes
at intermediate points~\cite{mohan:crashmonkey,pillai:appcrash}. Another line of
work has focused on fuzz testing as a way to induce crash-safety
bugs~\cite{xu:janus,kim:hydra}. These approaches have been successful for
finding bugs, including crash-safety bugs, but they only test sequential
executions, missing any bugs related to concurrency or crashes while multiple
threads are running. Furthermore, unlike formal verification, testing cannot
cover all executions of a program, even without crashes and concurrency,
potentially missing bugs.

The research community has also recognized the value of formal verification for
reasoning about a file-system implementation. The closest related work is
another verified, concurrent file system,
Flashix~\cite{bodenmuller:concurrent-flashix}. Flashix runs on top of a
lower-level storage technology, raw flash rather than an SSD. The techniques
developed to verify Flashix are specialized to this use case and not intended to
scale to a general-purpose file system. Its concurrency is primarily between
regular operations and garbage collection, and read-only concurrency. DaisyNFS
has a different file-system design with write-write concurrency and a general
crash safety solution using transactions, whereas Flashix accounts for flash
failures and thus crashes in every write to storage.

There are other verified file systems, especially the sequential file systems
FSCQ~\cite{chen:fscq} and Yggdrasil~\cite{sigurbjarnarson:yggdrasil} and an
in-memory but concurrent file system AtomFS~\cite{zou:atomfs}. These systems use
verification techniques that do not support both crashes and concurrency, and we
cannot extend them in a straightforward way to support the other form of reasoning.

\section{Challenges in implementing file systems}

Fundamentally a file system is a data structure that stores files inside a
hierarchy of directories. If this were an ordinary data structure it would be
fairly simple to implement correctly. However, the file system must persist all
of its data into disk blocks. Furthermore, we would like the file system to keep
stored data safe even if it is interrupted, which might happen due to a power
failure or sudden disconnect of the storage device; we call this property
``crash safety.'' Without appropriate care in the implementation, a naive
implementation could lose or corrupt data. Data loss is particularly bad when
metadata is corrupted --- for example, if a directory is moved by removing it
from its original parent and then adding it to the new parent, interrupting this
process might lose the directory and all of its contents.

Concurrency adds complexity on top of implementing the file system as a
crash-safe data structure. To get good performance, it is helpful to take
advantage of multiple CPUs to prepare concurrent operations. One of the slowest
parts of a file system is actually writing to stable storage, since writing to a
disk is slower than writing to memory. An efficient file system can take
advantage of concurrently-issued writes by coalescing them into a single write
to the disk, improving the throughput of the system.

With both crash safety and concurrency, there is a wide spectrum of guarantees
the file system might make about what happens with concurrent operations and
crashes. Informally we would like the system not to lose data, and we don't want
an unlucky interleaving of concurrent threads to have broad consequences like a
complete deadlock. Since this thesis is about using a proof to establish
correctness, we need a formal definition of correctness to prove.

Applications and users can have different expectations for what guarantees the
file system makes. We chose to implement the strongest guarantee for concurrency
and crash safety: every operation should appear to occur at a single instant in
time, or in other words should be atomic. This holds for concurrent threads as
well as if a system crashes and the system reboots. Operations that are in
progress might still be interrupted on crash, so data in the process of being
written will be lost, but this is unavoidable if the system never reached the
point of persisting that data.

File systems do offer weaker guarantees --- especially deferring when data is
durable, so recently-written data might be lost on crash but the system always
reverts to a consistent state --- it is generally more difficult to take
advantage of those weaker guarantees and prove that the system still meets its
specification. The NFS specification requires most operations to be persistent
when they return in any case, restricting when an NFS server can take advantage
of weaker durability guarantees. Instead of relaxing the guarantees we focused
on a fairly efficient implementation of our strong atomic specification.

Concurrency and crash safety can interact to make atomicity difficult to
achieve. To give a flavor of the kinds of interactions these two can bring
about, we give a simple example from the transaction system. Writes to the
transaction system are buffered in memory before being flushed to disk, with the
goal of coalescing concurrent transactions in a single flush. Perhaps
surprisingly, even if all writes are immediately followed by a flush, the system
does not appear to have atomically durable writes. If one thread writes, another
thread can concurrently read the buffered value before it is flushed, but a
crash immediately afterward will lose the write and revert to the old value.

\section{Approach}

What does it mean to give a machine checked, formal proof of a system? At a high
level, program proofs always have three components: an implementation, a
specification, and a proof. When doing machine-checked proofs, all three are
physically represented as code in a verification system. The verification system
checks the proof against the implementation and specification, ensuring that the
proof is complete.

This thesis integrates interactive, foundational proofs using custom
infrastructure (in Coq) as well as automated verification using a
verification-aware programming language (Dafny). These are both machine-checked,
formal proofs, but the interaction models of the two systems are different
enough that we explain them separately.

In Coq, the core feature is proofs based on dependent type theory, which is
expressive enough to represent essentially any math. A first step when using Coq
is to connect the code to a model in Coq. The model and its semantics encodes any
assumptions we make about how the program behaves; the rest of the proof will be
about these behaviors. The semantics is typically structured as a transition
system, where an execution is a sequence of states the program goes through
along with some notion of observable behavior, like external I/O or return
values. From now on this thesis will refer to the model as simply being the original
program being verified,
but we'll make a distinction when discussing what it means to have verified
the system.

Once we have a program in Coq, we can reason about it. The goal of
verification is to prove that the program meets its specification, and
specifications tend to give the allowed behaviors of the program. These
specifications forbid universally incorrect behavior, like reading an
out-of-bounds address in an array, but more precisely specify what the program's
allowed return values are. In principle it might be possible to prove a theorem
about all the behaviors of a program directly, but such a proof would be
monstrous to write, hard to split up, and challenging to maintain as the code
evolved.

A common structure to tame the complexity of reasoning about a program is to use
a \emph{program logic}. The program logic is a way of expressing and proving
statements about the program, including properties about individual functions
and language constructs like \cc{if}-statements and \cc{while}-loops. The proof
in a program logic will often mirror the structure of the code, since each
function has its own specification and groups of related functions have related
specs.

Program logics for concurrency are still an active area of research; only
recently have they reached the maturity to give completely mechanized proofs of
moderate-sized programs. There are few logics that also can reason about crash
safety. Our approach in this thesis is to build a new program logic with all the
concurrency-reasoning features of a modern program logic, plus new features for
reasoning about crashes. What makes this feasible is Iris, a modular framework
for concurrency. Iris includes a concurrent program logic which we are able to
extend with crash-safety reasoning while preserving the concurrency reasoning
features, without reimplementing them from scratch.

Using our new program logic, we verified GoTxn, a concurrent transaction system.
What we prove about the transaction system is that any program that uses
transactions really has transactional behavior: its execution is equivalent to a
version of the program where the transactions run atomically. The complete
specification includes some important details, but this intuition still holds.

Next, we use GoTxn in Dafny as the basis for a file system.
The transaction system is implemented as an ordinary Go package, with methods to
start a transaction, execute reads and writes within it, and finally commit or
abort it. Using Dafny's \cc{extern} feature we make these methods available with
assumed specifications that match the specifications proven in Coq.

Dafny verification works quite differently from Coq. Dafny is a programming
language with verification features; contrast this with Coq, which supports
general math that can \emph{model} programs. A Dafny method can be annotated
with a specification. The Dafny checker converts a method and its specification
to a logical formula, which is true if and only if the specification holds for
the method. It then queries a \emph{solver} to determine if the formula is true.
Contrast all of this with Coq, where the user manually develops the program
logic and connects the rules of this logic. The process cannot be perfectly
automated because it is impossible to answer whether a general logical formula
is true or not, but the user can insert annotations to help out the solver, and
generally fewer annotations are needed than lines of proof for Coq. The main
downside to this approach is that it fixes a sequential programming language, so
unlike Coq it isn't possible to reason about concurrency and crashes.

One of the contributions of this thesis is that the file-system design isolates
concurrency and crash safety into the transaction system. This structure leaves
the rest of the implementation only to \emph{sequentially} implement the
file-system logic and data structures. Because this is sequential, crash-free
execution, we use Dafny to implement and verify each operation, then run this
code wrapped in a transaction. Later we will have more to say about the file
system's proof, but for now suffice it to say that we show it correctly
implements the NFS protocol.

\tej{we haven't been putting emphasis on linking; especially strange to be the conclusion}
Since we use two different formal systems, we do not set up and prove a single,
unified theorem about the whole file system, which is indeed not even
implemented in one language. Instead, the file system is compiled by linking the
Dafny code, after compilation to Go, with the transaction system. Similar to
this code linking step, we prove a linking theorem, showing that the proof from
Coq and proof from Dafny compose properly. The proofs from both systems are
checked automatically so we call them mechanized, but this final linking step is
outside of both systems so we must give it on paper. However, we take care to
make the transaction system's specification strong enough that the two theorems
compose easily. Later we discuss what parts of the system are \emph{trusted} to
guarantee that the whole system is correct; notably, we learn from Coq and Dafny
that the transaction system and file-system code are independently correct, and
the trust only lies in the interface between them.
