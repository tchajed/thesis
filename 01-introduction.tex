One crucial service in an operating system is its \emph{file system}, the piece
of software that takes a disk (which simply stores a long sequence of bytes) and
makes it more useful by giving applications the abstraction of files and directories. The file
system is important because applications rely on it to store data, and to
persist that data even if the computer shuts down (perhaps unexpectedly, say due
to a power failure) and reboots. Due to their importance to nearly all applications, many
file systems have internally complicated implementations, with optimizations and
concurrency for high performance. However, due to this complexity, file systems
sometimes have bugs, especially subtle bugs that only manifest if the system
crashes at an inopportune time or if concurrent operations interleave in just
the wrong way. These bugs can result in the file system misbehaving, for example
losing files when the file system's internals are corrupted.

A file system's developers generally use testing to identify and fix bugs in the
implementation. Unfortunately, testing is fundamentally difficult due to the
combination of a concurrent implementation and the requirement that the file
system be correct even when the computer crashes. Both of these facets of a file
system mean even a handful of operations can have a large number of possible
executions, making it difficult to test all of them and gain high confidence in the
implementation.

This thesis takes an alternate approach to testing to obtain a correct file
system: we formally verify a new file-system implementation against a high-level
specification of the file system's behavior. The high-level approach of this
thesis is to \emph{implement} a file system, define a mathematical
\emph{specification} of what the file system is supposed to do, and then
\emph{prove} that the implementation always meets the specification regardless
of how the program executes, and even if the system crashes. To increase confidence in
the proof, we carry it out with a computer and a piece of software called a
\emph{proof assistant} checks that the proof is valid. The nature of these
proofs mean they force the developer to systematically cover every corner case
in the code.

The thesis's contributions address two main challenges in verifying a file system. The
first challenge is reasoning about the combination of crash safety and
concurrency at all, for which we build a framework that applies to efficient
code (written in Go) and supports the reasoning required for the file-system implementation.
The second challenge is the complexity of the implementation, which we address
with a novel, verification-friendly file-system design that allows us to reason
about each operation as if it were atomic, resulting in much simpler sequential reasoning.

More concretely the verified
artifact from this thesis is \textbf{DaisyNFS}, which implements the Network
File System (NFS) protocol on top of a disk with block-based access. NFS is a
standard file-system protocol intended for accessing a file system over a network.
We chose to
implement NFS since it is widely used, and the behavior of an NFS server is relatively well-specified
by the RFC 1813 standard, compared to the requirements on a Linux file system,
for example. The specification for our file system stipulates that each
operation appears to execute all at once --- that is, atomically --- with
respect to both other threads and on crash, and that every operation behaves
according to our mathematical model of the NFS specification.

DaisyNFS has a novel file-system design where all disk access goes through a
\emph{transaction system} called \textbf{GoTxn}. The advantage of this design is that the
transaction system makes calling code appear to run in sequential transactions,
isolating crash safety and concurrency concerns to the transaction system
implementation. The file-system code can then be verified with sequential
reasoning, a principle formalized in our \emph{simulation-transfer theorem}.
As a side effect of having simpler sequential reasoning, we were
able to focus our effort on writing file-system features and getting good
performance. While other file systems (including the most common Linux file
system, ext4, and the Windows NTFS file system) have mechanisms for crash atomicity, DaisyNFS
uses transactions to generically handle both crash and concurrency atomicity.

A key technical contribution that allows us to verify this file-system design is
a formal specification of how the transaction system guarantees atomicity,
expressed using a specification called \emph{program refinement}. Our
formal specification is backed by a machine-checked proof against the GoTxn
implementation, giving confidence that this specification is actually achieved.
A challenge in this specification is formalizing under what conditions the
transaction system is able to guarantee atomicity --- for example, transactions
that read or write global state outside the transaction system cannot be made atomic.

The transaction system has a high-performance implementation with tricky
concurrency. Performance is important for this layer since it is the
bottleneck for the file-system's performance. This thesis develops new
foundations that make this reasoning possible for efficient implementations:
\textbf{Perennial} is a new program logic for
reasoning about the combination of concurrency and crash safety, and
\textbf{Goose} is a tool for reasoning about a Go implementation using Perennial.

The main result of this thesis is DaisyNFS, a verified, concurrent, and
crash-safe file system. DaisyNFS implements the NFSv3 protocol, a standard protocol for exposing
a file system over the network. We use DaisyNFS by mounting it with the
Linux NFS client and then interacting with the mounted file system using
the standard system-call API.\@ A performance evaluation of DaisyNFS shows
that it is competitive with the Linux kernel NFS server exporting an
ext4 file system.

\section{State of the art}

Production file systems are generally validated by testing. While testing is
indispensable for development, the nature of a file system makes it difficult to
catch all bugs with only testing. The fundamental difficulty is a high degree of
non-determinism from two sources: crashes in the middle of execution, and
concurrency in the implementation that is needed for good performance.

The importance of file-system correctness has been recognized by the academic
community, thus there are many approaches for increasing confidence with
improved testing. One line of work has explored systematically testing crashes
at intermediate points~\cite{mohan:crashmonkey,pillai:appcrash}. Another line of
work has focused on fuzz testing as a way to induce crash-safety
bugs~\cite{xu:janus,kim:hydra}. These approaches have been successful for
finding bugs, including crash-safety bugs, but they only test sequential
executions, missing any bugs related to concurrency or crashes while multiple
threads are running. Furthermore, unlike formal verification, testing cannot
cover all executions of a program, even without crashes and concurrency,
potentially missing bugs.

The research community has also recognized the value of formal verification for
reasoning about a file-system implementation. The closest related work is
another verified, concurrent file system,
Flashix~\cite{bodenmuller:concurrent-flashix}. Flashix runs on top of a
lower-level storage technology, raw flash rather than an SSD. The techniques
developed to verify Flashix are specialized to this use case and not intended to
scale to a general-purpose file system. Its concurrency is primarily between
regular operations and garbage collection, and read-only concurrency. DaisyNFS
has a different file-system design with write-write concurrency and a general
crash safety solution using transactions, whereas Flashix accounts for flash
failures and thus crashes in every write to storage.

There are other verified file systems, especially the sequential file systems
FSCQ~\cite{chen:fscq} and Yggdrasil~\cite{sigurbjarnarson:yggdrasil} and an
in-memory but concurrent file system AtomFS~\cite{zou:atomfs}. These systems use
verification techniques that do not support both crashes and concurrency, and we
cannot extend them in a straightforward way to support the other form of reasoning.

\section{Challenges in implementing file systems}

Fundamentally a file system is a data structure that stores files inside a
hierarchy of directories. If this were an ordinary data structure it would be
fairly simple to implement correctly. However, the file system must persist all
of its data into disk blocks. Furthermore, we would like the file system to keep
stored data safe even if it is interrupted, which might happen due to a power
failure or sudden disconnect of the storage device; we call this property
``crash safety.'' Without appropriate care in the implementation, a naive
implementation could lose or corrupt data. Data loss is particularly bad when
metadata is corrupted --- for example, if a directory is moved by removing it
from its original parent and then adding it to the new parent, interrupting this
process might lose the directory and all of its contents.

To get good performance, it is helpful to take advantage of multiple CPUs to
prepare concurrent operations. However, this concurrency adds complexity on top
of implementing the file system as a crash-safe data structure. Concurrency and
storage also interact, since an efficient file system will improve performance
by taking advantage of concurrently-issued writes to combine multiple disk
operations into one.

With both crash safety and concurrency, there is a wide spectrum of guarantees
the file system might make about what happens with concurrent operations and
crashes. The informal goal is for the system to never lose data, and we don't want
an unlucky interleaving of concurrent threads to have broad consequences like a
complete deadlock. For the approach of this thesis, we need a more formal
definition of correctness to prove that the system meets.

Applications and users can have different expectations for what guarantees the
file system makes. We chose to implement the strongest guarantee for concurrency
and crash safety: every operation should appear to occur at a single instant in
time, or in other words should be atomic. This holds for concurrent threads as
well as if a system crashes and the system reboots. Operations that are in
progress might still be interrupted on crash, so data in the process of being
written will be lost, but this is unavoidable if the system never reached the
point of persisting that data.

File systems do offer weaker guarantees --- especially allowing recently-written
data to be lost on crash in order to defer when data is
durable --- it is generally more difficult to take
advantage of those weaker guarantees and prove that the system still meets its
specification. The NFS specification requires most operations to be persistent
when they return in any case, restricting when an NFS server can take advantage
of weaker durability guarantees. Instead of relaxing the guarantees we focused
on a fairly efficient implementation of our strong atomic specification.

Concurrency and crash safety can interact to make atomicity difficult to
achieve. To give a flavor of the kinds of interactions these two can bring
about, we give a simple example from the transaction system. Writes to the
transaction system are buffered in memory before being flushed to disk, with the
goal of coalescing concurrent transactions in a single flush. Perhaps
surprisingly, even if all writes are immediately followed by a flush, the system
does not appear to have atomically durable writes. If one thread writes, another
thread can concurrently read the buffered value before it is flushed, but a
crash immediately afterward will lose the write and revert to the old value.

\tej{add more discussion about bugs?}

\section{Approach}

What does it mean to give a machine checked, formal proof of a system? At a high
level, program proofs always have three components: an implementation, a
specification, and a proof. When doing machine-checked proofs, all three are
physically represented as code in a verification system. The verification system
checks the proof against the implementation and specification, ensuring that the
proof is complete.

\tej{some diagram with how the pieces fit together would be good, perhaps like
the talk's implementation slide}

This thesis integrates interactive, foundational proofs using custom
infrastructure (in Coq) as well as automated verification using a
verification-aware programming language (Dafny). These are both machine-checked,
formal proofs, but the interaction models of the two systems are different
enough that we explain them separately.

In Coq, the core feature is proofs based on dependent type theory, which is
expressive enough to represent essentially any math. A first step when using Coq
is to connect the code to a model in Coq. The model and its semantics encodes any
assumptions we make about how the program behaves; the rest of the proof will be
about these behaviors. The semantics is typically structured as a transition
system, where an execution is a sequence of states the program goes through
along with some notion of observable behavior, like external I/O or return
values. From now on this thesis will refer to the model as simply being the original
program being verified,
but we'll make a distinction when discussing what it means to have verified
the system.

Once we have a program in Coq, we can reason about it. The goal of
verification is to prove that the program meets its specification, and
specifications tend to give the allowed behaviors of the program. These
specifications forbid universally incorrect behavior, like reading an
out-of-bounds address in an array, but more precisely specify what the program's
allowed return values are. In principle it might be possible to prove a theorem
about all the behaviors of a program directly, but such a proof would be
monstrous to write, hard to split up, and challenging to maintain as the code
evolved.

A common structure to tame the complexity of reasoning about a program is to use
a \emph{program logic}. The program logic is a way of expressing and proving
statements about the program, including properties about individual functions
and language constructs like \cc{if}-statements and \cc{while}-loops. The proof
in a program logic will often mirror the structure of the code, since each
function has its own specification and groups of related functions have related
specs.

Program logics for concurrency are still an active area of research; only
recently have they reached the maturity to give completely mechanized proofs of
moderate-sized programs. There are few logics that also can reason about crash
safety. Our approach in this thesis is to build a new program logic with all the
concurrency-reasoning features of a modern program logic, plus new features for
reasoning about crashes. What makes this feasible is Iris, a modular framework
for concurrency. Iris includes a concurrent program logic which we are able to
extend with crash-safety reasoning while preserving the concurrency reasoning
features, without reimplementing them from scratch.

Using our new program logic, we verified GoTxn, a concurrent transaction system.
What we prove about the transaction system is that any program that uses
transactions really has transactional behavior: its execution is equivalent to a
version of the program where the transactions run atomically. The complete
specification includes some important details, but this intuition still holds.

Next, we use GoTxn in Dafny as the basis for a file system.
The transaction system is implemented as an ordinary Go package, with methods to
start a transaction, execute reads and writes within it, and finally commit or
abort it. Using Dafny's \cc{extern} feature we make these methods available with
assumed specifications that match the specifications proven in Coq.

Dafny verification works quite differently from Coq. Dafny is a programming
language with verification features; contrast this with Coq, which supports
general math that can \emph{model} programs. A Dafny method can be annotated
with a specification. The Dafny checker converts a method and its specification
to a logical formula, which is true if and only if the specification holds for
the method. It then queries a \emph{solver} to determine if the formula is true.
Contrast all of this with Coq, where the user manually develops the program
logic and connects the rules of this logic. The process cannot be perfectly
automated because it is impossible to answer whether a general logical formula
is true or not, but the user can insert annotations to help out the solver, and
generally fewer annotations are needed than lines of proof for Coq. The main
downside to this approach is that it fixes a sequential programming language, so
unlike Coq it isn't possible to reason about concurrency and crashes.

One of the contributions of this thesis is that the file-system design isolates
concurrency and crash safety into the transaction system. This structure leaves
the rest of the implementation only to \emph{sequentially} implement the
file-system logic and data structures. Because this is sequential, crash-free
execution, we use Dafny to implement and verify each operation, then run this
code wrapped in a transaction. Later we will have more to say about the file
system's proof, but for now suffice it to say that we show it correctly
implements the NFS protocol.

In order to connect the file system's sequential proofs to its concurrent
execution, we prove a general theorem about the transaction system's
implementation. The starting point is the idea of a \emph{simulation} proof,
which shows that a system like the file-system transactions correctly implement an
abstract specification like the NFS protocol transitions. The GoTxn
\emph{simulation-transfer theorem} shows that for any system implemented using
transactions with a sequential simulation proof, the concurrent system running
with GoTxn concurrently simulates its abstract specification where each
operation is atomic. Intuitively this theorem holds because every concurrent
execution of the GoTxn transactions appears to be atomic, and then the
sequential simulation proof shows those atomic transactions implement the
abstract specification. However, the GoTxn theorem formalizes precisely what
conditions are required for the simulation transfer, including restrictions on
the transactions and exactly what crash safety guarantees are achieved.

\section{Contributions}

This thesis makes several contributions that enable its overall goal of a
verified, concurrent file system.

\begin{itemize}
  \item \textbf{Perennial} has new techniques for reasoning about crash safety
        and concurrency using specifications based on crash weakest
        preconditions. These include crash conditions combined with concurrency
        and reasoning principles for moving ownership to a recovery procedure
        following a crash. \textbf{Logically atomic crash specifications} are a
        pattern using Perennial's crash weakest preconditions for specifying
        libraries that have both concurrent behavior and involve persistent
        state. These are implemented using Perennial and used in the GoTxn
        proof.
  \item GoTxn has a new \textbf{lifting-based specification} for its journaling
        layer to reason about concurrent transactions separately, which is
        challenging since the logical disk can change during one transaction due
        to a concurrent commit. Its proof uses a novel \textbf{history-based
        abstract state} for the write-ahead log. This model allowed us to carry
        out a modular proof where the write-ahead logging library hides most of
        its internal complexity, simplifying reasoning about rest of the GoTxn
        code that uses it. Finally, GoTxn exports a \textbf{program refinement}
        specification that captures how transactions appear to run atomically.
  \item DaisyNFS uses a \textbf{simulation-transfer theorem}, proven on top of
        GoTxn's program refinement specification, which shows that sequential
        reasoning for each transaction in a system implies correctness for the
        whole system when run on top of GoTxn. This justifies using Dafny, a
        sequential verification language, to verify the DaisyNFS implementation.
  \item \textbf{Goose} connects efficient code implemented in Go to a model of
        that code in Perennial. A general contribution here is a design for
        systems verification that enables efficient code and convenient
        reasoning. Goose includes reasoning principles for the models that it
        outputs, to support verifying the translated code.
\end{itemize}

The ideas in Perennial and Goose are applied to GoTxn, but they could be used
for reasoning about other concurrent storage systems written in Go. Similarly,
this thesis applied GoTxn to a verified file system, but it could also be used
as the basis for other verified storage systems, like a persistent key-value
store.

\section{Reading guide for the thesis}
\label{sec:intro:reading-guide}

The chapters of the thesis are intended to be as independent as possible, with
only a few dependencies. Most of the thesis is written for a broad systems
audience, except for the Perennial chapter which has a more programming
languages-oriented audience.

\Cref{ch:related} covers related work across Perennial, GoTxn, and DaisyNFS.

\Cref{ch:perennial} is an overview of Perennial. This chapter is oriented
towards a reader interested in the general verification concepts and not
necessarily the systems side. At this level of abstraction Perennial is
independent of both the GoTxn proof and even Goose for verifying Go code.

\Cref{ch:crash-logatom} describes a style of logically atomic specifications
that capture both concurrency and crash atomicity using Perennial. It uses an
extended example from the GoTxn proof and explains its formal underpinnings at a
high level.

\Cref{ch:txn} describes the GoTxn proof, going up to the program refinement
specification. It incorporates the GoJournal paper~\cite{chajed:gojournal} and
parts of the DaisyNFS paper~\cite{chajed:daisy-nfs}. An important part of GoTxn
is its specification, which captures how transactions are atomic. This chapter
does not require the full Perennial or logical atomicity chapters.

\Cref{ch:daisy-nfs} describes the design and proof of DaisyNFS.\@ This chapter
explains the simulation-transfer theorem, which justifies using Dafny to verify
DaisyNFS even though Dafny is a sequential verification tool and DaisyNFS is a
concurrent system.

\Cref{ch:goose} is about Goose and talks about verifying Go code generally, with
nothing specific to GoTxn or even storage systems. There is the first detailed
description of Goose, so this chapter is written to be readable without any of
the other chapters.
