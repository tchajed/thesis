One crucial service in an operating system is its \emph{file system}, the piece
of software that takes a disk (which simply stores a long sequence of bytes) and
makes it more useful by giving applications the abstraction of files and directories. The file
system is important because applications rely on it to store data, and to
persist that data even if the computer shuts down (perhaps unexpectedly, say due
to a power failure) and reboots. Due to their importance to nearly all applications, many
file systems have internally complicated implementations, with optimizations and
concurrency for high performance. However, due to this complexity, file systems
sometimes have bugs, especially subtle bugs that only manifest if the system
crashes at an inopportune time or if concurrent operations interleave in just
the wrong way. These bugs can result in the file system misbehaving, for example
losing files when the file system's internals are corrupted.

A file system's developers generally use testing to identify and fix bugs in the
implementation. Unfortunately, testing is fundamentally difficult due to the
combination of a concurrent implementation and the requirement that the file
system be correct even when the computer crashes. Both of these facets of a file
system mean even a handful of operations can have a large number of possible
executions, making it difficult to test all of them and gain high confidence in the
implementation.

This thesis takes an alternate approach to testing to obtain a correct file
system: we formally verify a new file-system implementation against a high-level
specification of the file system's behavior. The high-level approach of this
thesis is to \emph{implement} a file system, define a mathematical
\emph{specification} of what the file system is supposed to do, and then
\emph{prove} that the implementation always meets the specification regardless
of how the program executes and even under crashes. To increase confidence in
the proof, we carry it out with a computer; such a machine-checked proof
formalizes the proof as code that is automatically checked
for correctness against the specification and implementation.

The thesis's contributions address two main challenges in verifying a file system. The
first challenge is reasoning about the combination of crash safety and
concurrency at all, for which we build a framework that applies to efficient
code (written in Go) and can handle the sorts of reasoning in the file system.
The second challenge is the complexity of the implementation, which we address
with a novel, verification-friendly file-system design that allows us to reason
about each operation as if it were atomic, resulting in much simpler sequential reasoning.

More concretely the verified
artifact from this thesis is \textbf{DaisyNFS}, which implements the Network
File System (NFS) protocol on top of a disk with block-based access. NFS is a
widely-used protocol for exporting a file system across a network. We chose to
implement NFS since the behavior of an NFS server is relatively well-specified
by the RFC 1813 standard, compared to the requirements on a Linux file system,
for example. The specification for our file system stipulates that each
operation is implemented atomically (with respect to both other threads and on
crash), and behaves according to a formal model of the NFS specification as laid
out in prose in RFC 1813.

DaisyNFS has a novel file-system design where all disk access goes through a
\emph{transaction system} we call GoTxn. The advantage of this design is that the
transaction system makes calling code appear to run in sequential transactions,
isolating crash safety and concurrency concerns to the transaction system
implementation. As a side effect of having simpler sequential reasoning, we were
able to focus our effort on writing file-system features and getting good
performance. While other file systems (including the most common Linux file
system, ext4, and the Windows NTFS file system) also use transactions, DaisyNFS
uses them in a principled way such that every file-system operation is
automatically made atomic. In many other file systems there remains state
outside the transaction system, resulting in a subtle implementation where the
developer must still coordinate between the updates within a transaction and the
updates outside, for example by adding additional locking.

A key technical contribution that allows us to verify this file-system design is
a formal specification of how the transaction system guarantees atomicity. Our
formal specification is backed by a machine-checked proof against the GoTxn
implementation, giving confidence that this specification is actually achieved.
A challenge in this specification is formalizing under what conditions the
transaction system is able to guarantee atomicity --- for example, transactions
that read or write global state outside the transaction system cannot be made atomic.

The transaction system has a high-performance implementation since it is the
bottleneck for the file-system's performance, resulting in tricky concurrency
and crash safety patterns. This thesis develops new foundations that make this
reasoning possible for efficient implementations: \textbf{Perennial} is a new program logic for
reasoning about the combination of concurrency and crash safety, and
\textbf{Goose} is a tool for reasoning about a Go implementation using Perennial.

The main result of this thesis is the techniques and design of a verified,
concurrent file system. Several contributions support this goal:
\begin{itemize}
  \item \textbf{Perennial} has new techniques for reasoning about crash safety
    and concurrency. For example, Perennial integrates crash conditions into a
    concurrent separation logic.
  \item \textbf{Goose} connects efficient code implemented in Go to Perennial.
    Goose is an interesting point in the design space for connecting code
    and proofs. Some general contributions here are the model and
    verification principles for systems code, like how structs and slices
    (dynamically-sized arrays) are handled.
  \item \textbf{GoTxn}'s proof has a new lifting-based specification to reason
    about concurrent transactions separately. The model of the write-ahead
    log is another contribution that enabled carrying out the proof in a modular
    way.
  \item GoTxn's \textbf{simulation-transfer theorem} captures how atomic
    transactions enable sequential reasoning for a system implemented on top
    even though the systme is concurrent. This justifies using sequential proofs
    for the file system.
  \item \textbf{DaisyNFS} is a file system that uses GoTxn's transactions. The
    proof of its correctness uses Dafny, a
    sequential verification language, to reason about each transaction.
\end{itemize}

DaisyNFS implements the NFSv3 protocol, a standard protocol for exposing
a file system over the network. We use DaisyNFS by mounting it with the
Linux NFS client and then interacting with the mounted file system using
the standard system-call API.\@ A performance evaluation of DaisyNFS shows
that it is competitive with the Linux kernel NFS server exporting an
ext4 file system.

\section{State of the art}

Production file systems are generally validated by testing. While testing is
indispensible for development, the nature of a file system makes it difficult to
catch all bugs with only testing. The fundamental difficulty is a high degree of
non-determinism from two sources: crashes in the middle of execution, and
concurrency in the implementation that is needed for good performance.

The importance of file-system correctness has been recognized by the academic
community, thus there are many approaches for increasing confidence with
improved testing. One line of work has explored systematically testing crashes
at intermediate points~\cite{mohan:crashmonkey,pillai:appcrash}. Another line of
work has focused on fuzz testing as a way to induce crash-safety
bugs~\cite{xu:janus,kim:hydra}. These approaches have been successful for
finding bugs, including crash-safety bugs, but they only test sequential
executions, missing any bugs related to concurrency or crashes while multiple
threads are running. Furthermore, unlike formal verification, testing cannot
cover all executions of a program, even without crashes and concurrency,
potentially missing bugs.

The research community has also recognized the value of formal verification for
reasoning about a file-system implementation. The closest related work is
another verified, concurrent file system,
Flashix~\cite{bodenmuller:concurrent-flashix}. Flashix runs on top of a
lower-level storage technology, raw flash rather than an SSD. The techniques
developed to verify Flashix are specialized to this use case and not intended to
scale to a general-purpose file system. Its concurrency is primarily between
regular operations and garbage collection, and read-only concurrency. DaisyNFS
has a different file-system design with write-write concurrency and a general
crash safety solution using transactions, whereas Flashix accounts for flash
failures and thus crashes in every write to storage.

There are other verified file systems, especially the sequential file systems
FSCQ~\cite{chen:fscq} and Yggdrasil~\cite{sigurbjarnarson:yggdrasil} and an
in-memory but concurrent file system AtomFS~\cite{zou:atomfs}. These systems use
verification techniques that do not support both crashes and concurrency, and we
cannot extend them in a straightforward way to support the other form of reasoning.

\section{Challenges in implementing file systems}

Fundamentally a file system is a data structure that stores files inside a
hierarchy of directories. If this were an ordinary data structure it would be
fairly simple to implement correctly. However, the file system must persist all
of its data into disk blocks. Furthermore, we would like the file system to keep
stored data safe even if it is interrupted, which might happen due to a power
failure or sudden disconnect of the storage device; we call this property
``crash safety.'' Without appropriate care in the implementation, a naive
implementation could lose or corrupt data. Data loss is particularly bad when
metadata is corrupted --- for example, if a directory is moved by removing it
from its original parent and then adding it to the new parent, interrupting this
process might lose the directory and all of its contents.

Concurrency adds complexity on top of implementing the file system as a
crash-safe data structure. To get good performance, it is helpful to take
advantage of multiple CPUs to prepare concurrent operations. One of the slowest
parts of a file system is actually writing to stable storage, since writing to a
disk is slower than writing to memory. An efficient file system can take
advantage of concurrently-issued writes by coalescing them into a single write
to the disk, improving the throughput of the system.

With both crash safety and concurrency, there is a wide spectrum of guarantees
the file system might make about what happens with concurrent operations and
crashes. Informally we would like the system not to lose data, and we don't want
an unlucky interleaving of concurrent threads to have broad consequences like a
complete deadlock. Since this thesis is about using a proof to establish
correctness, we need a formal definition of correctness to prove.

Applications and users can have different expectations for what guarantees the
file system makes. We chose to implement the strongest guarantee for concurrency
and crash safety: every operation should appear to occur at a single instant in
time, or in other words should be atomic. This holds for concurrent threads as
well as if a system crashes and the system reboots. Operations that are in
progress might still be interrupted on crash, so data in the process of being
written will be lost, but this is unavoidable if the system never reached the
point of persisting that data.

File systems do offer weaker guarantees --- especially allowing recently-written
data to be lost on crash in order to defer when data is
durable --- it is generally more difficult to take
advantage of those weaker guarantees and prove that the system still meets its
specification. The NFS specification requires most operations to be persistent
when they return in any case, restricting when an NFS server can take advantage
of weaker durability guarantees. Instead of relaxing the guarantees we focused
on a fairly efficient implementation of our strong atomic specification.

Concurrency and crash safety can interact to make atomicity difficult to
achieve. To give a flavor of the kinds of interactions these two can bring
about, we give a simple example from the transaction system. Writes to the
transaction system are buffered in memory before being flushed to disk, with the
goal of coalescing concurrent transactions in a single flush. Perhaps
surprisingly, even if all writes are immediately followed by a flush, the system
does not appear to have atomically durable writes. If one thread writes, another
thread can concurrently read the buffered value before it is flushed, but a
crash immediately afterward will lose the write and revert to the old value.

\tej{add more discussion about bugs?}

\section{Approach}

What does it mean to give a machine checked, formal proof of a system? At a high
level, program proofs always have three components: an implementation, a
specification, and a proof. When doing machine-checked proofs, all three are
physically represented as code in a verification system. The verification system
checks the proof against the implementation and specification, ensuring that the
proof is complete.

\tej{some diagram with how the pieces fit together would be good, perhaps like
the talk's implementation slide}

This thesis integrates interactive, foundational proofs using custom
infrastructure (in Coq) as well as automated verification using a
verification-aware programming language (Dafny). These are both machine-checked,
formal proofs, but the interaction models of the two systems are different
enough that we explain them separately.

In Coq, the core feature is proofs based on dependent type theory, which is
expressive enough to represent essentially any math. A first step when using Coq
is to connect the code to a model in Coq. The model and its semantics encodes any
assumptions we make about how the program behaves; the rest of the proof will be
about these behaviors. The semantics is typically structured as a transition
system, where an execution is a sequence of states the program goes through
along with some notion of observable behavior, like external I/O or return
values. From now on this thesis will refer to the model as simply being the original
program being verified,
but we'll make a distinction when discussing what it means to have verified
the system.

Once we have a program in Coq, we can reason about it. The goal of
verification is to prove that the program meets its specification, and
specifications tend to give the allowed behaviors of the program. These
specifications forbid universally incorrect behavior, like reading an
out-of-bounds address in an array, but more precisely specify what the program's
allowed return values are. In principle it might be possible to prove a theorem
about all the behaviors of a program directly, but such a proof would be
monstrous to write, hard to split up, and challenging to maintain as the code
evolved.

A common structure to tame the complexity of reasoning about a program is to use
a \emph{program logic}. The program logic is a way of expressing and proving
statements about the program, including properties about individual functions
and language constructs like \cc{if}-statements and \cc{while}-loops. The proof
in a program logic will often mirror the structure of the code, since each
function has its own specification and groups of related functions have related
specs.

Program logics for concurrency are still an active area of research; only
recently have they reached the maturity to give completely mechanized proofs of
moderate-sized programs. There are few logics that also can reason about crash
safety. Our approach in this thesis is to build a new program logic with all the
concurrency-reasoning features of a modern program logic, plus new features for
reasoning about crashes. What makes this feasible is Iris, a modular framework
for concurrency. Iris includes a concurrent program logic which we are able to
extend with crash-safety reasoning while preserving the concurrency reasoning
features, without reimplementing them from scratch.

Using our new program logic, we verified GoTxn, a concurrent transaction system.
What we prove about the transaction system is that any program that uses
transactions really has transactional behavior: its execution is equivalent to a
version of the program where the transactions run atomically. The complete
specification includes some important details, but this intuition still holds.

Next, we use GoTxn in Dafny as the basis for a file system.
The transaction system is implemented as an ordinary Go package, with methods to
start a transaction, execute reads and writes within it, and finally commit or
abort it. Using Dafny's \cc{extern} feature we make these methods available with
assumed specifications that match the specifications proven in Coq.

Dafny verification works quite differently from Coq. Dafny is a programming
language with verification features; contrast this with Coq, which supports
general math that can \emph{model} programs. A Dafny method can be annotated
with a specification. The Dafny checker converts a method and its specification
to a logical formula, which is true if and only if the specification holds for
the method. It then queries a \emph{solver} to determine if the formula is true.
Contrast all of this with Coq, where the user manually develops the program
logic and connects the rules of this logic. The process cannot be perfectly
automated because it is impossible to answer whether a general logical formula
is true or not, but the user can insert annotations to help out the solver, and
generally fewer annotations are needed than lines of proof for Coq. The main
downside to this approach is that it fixes a sequential programming language, so
unlike Coq it isn't possible to reason about concurrency and crashes.

One of the contributions of this thesis is that the file-system design isolates
concurrency and crash safety into the transaction system. This structure leaves
the rest of the implementation only to \emph{sequentially} implement the
file-system logic and data structures. Because this is sequential, crash-free
execution, we use Dafny to implement and verify each operation, then run this
code wrapped in a transaction. Later we will have more to say about the file
system's proof, but for now suffice it to say that we show it correctly
implements the NFS protocol.

In order to connect the file system's sequential proofs to its concurrent
execution, we prove a general theorem about the transaction system's
implementation. The starting point is the idea of a \emph{simulation} proof,
which shows that a system like the file-system transactions correct implement an
abstract specification like the NFS protocol transitions. The GoTxn
\emph{simulation-transfer theorem} shows that for any system implemented using
transactions with a sequential simulation proof, the concurrent system running
with GoTxn concurrently simulates its abstract specification where each
operation is atomic. Intuitively this theorem holds because every concurrent
execution of the GoTxn transactions appears to be atomic, and then the
sequential simulation proof shows those atomic transactions implement the
abstract specification. However, the GoTxn theorem formalizes precisely what
conditions are required for the simulation transfer, including restrictions on
the transactions and exactly what crash safety guarantees are achieved.

\subsection{Contributions}

\tej{why is there another contributions section? maybe just move the first
section here?}

The thesis makes contributions at each layer of the verification stack.
Organized in terms of systems:

\begin{itemize}
  \item Perennial is the first verification framework for reasoning about crash
        safety and concurrency. It is a program logic that proves theorems about
        the behavior of a concurrent system, including the possibility of
        crashing and rebooting at any time.
  \item Goose is a tool for verifying Go programs with Perennial. While the
        specific ideas show up in other projects, Goose combines them into a
        practical system that enabled verification of GoTxn using Perennial.
  \item GoTxn is a high-performance, verified transaction system. The
        top-level specification and proof of GoTxn are novel, especially because
        they are backed by a machine-checked proof against an implementation
        rather than only abstract. The proof uses new proof techniques to
        verify layers of the storage stack independently and then compose the
        proofs together.
  \item DaisyNFS is a file system with a novel design based on transactions.
        With the specification implemented by GoTxn, DaisyNFS is able to reason
        about each transaction body sequentially. Because reasoning is
        completely sequential, the proof is written in Dafny and exhibits a high
        degree of automation.
\end{itemize}

The ideas in Perennial and Goose are applied to GoTxn, but they could be used
for reasoning about other concurrent storage systems written in Go. Similarly,
this thesis applied GoTxn to a verified file system, but it could also be used
as the basis for other verified storage systems, like a persistent key-value
store. It is possible to build upon GoTxn within Perennial (including using the
journal and manually reasoning about locking and concurrency), or to follow the
DaisyNFS design and verify each transaction in Dafny.

\subsection{Reading guide for the thesis}

The thesis has five chapters that are intended to be fairly independent.

\Cref{sec:related} covers related work across Perennial, GoTxn, and DaisyNFS.

\Cref{sec:goose} is about Goose and talks about verifying Go code generally,
with nothing specific to GoTxn or even storage systems. There is the first
complete description of Goose (the CoqPL paper~\cite{chajed:goose-coqpl} is both
short and out-of-date), so this chapter is written to be readable without any of
the other chapters.

\Cref{sec:perennial} is an overview of Perennial. The examples in
\cref{sec:perennial:crash-hocap} are taken from GoTxn, so they will also help
explain how that proof works.

\Cref{sec:txn} describes the GoTxn specification and proof. It incorporates the
GoJournal paper~\cite{chajed:gojournal} and parts of the DaisyNFS
paper~\cite{chajed:daisy-nfs}. This chapter does not require the understanding
the Perennial chapter. An important part of GoTxn is its specification, which
enables the connection to Dafny.

\Cref{sec:daisy-nfs} describes the design and proof of DaisyNFS.\@ This chapter
explains in more detail how the GoTxn proof is connected to Dafny. Here we also
evaluate the file system's correctness guarantees and performance.
