DaisyNFS draws on several lines of research. This chapter both explains the
research DaisyNFS directly builds upon and other work solving similar problems.

\resume

\section{The Flashix file system}

The Flashix project deserves special attention since it also develops a verified
concurrent and crash-safe file system~\cite{bodenmuller:concurrent-flashix}.
Flashix targets flash storage, a lower-level storage technology than the drives
that DaisyNFS targets. The project has different goals around concurrency,
extending a sequential verified file system with limited concurrency. Flashix
has an idiosyncratic approach to reasoning about concurrency and crashes
specific to their file-system design, as opposed to Perennial's general
reasoning principles. Flashix is implemented using abstract data types in a
high-level language; a code generator transforms this code into executable C,
but this process is both not verified and has difficulty producing the most
efficient code using in-place updates.

While Flashix does have mechanized proofs, the approaches for both concurrency
and crash safety are layered on top in such a way that the top-level
specification and proof are not entirely within the proof assistant. Perennial
on the other hand formalizes the complete specification down to a simple
semantics for crashes and concurrency. Flashix also effectively has crash
reasoning throughout the system, whereas DaisyNFS factors out this reasoning to
GoTxn and then layers sequential proofs on top.

The Flashix project found that components in the stack intertwine due to the
realism of the system; modularity helped but the interfaces still had many
dependencies. We had a similar experience within the transaction system, where
performance constrained the APIs of internal layers and forced us to export
complicated APIs. GoTxn was perhaps trickier than the components of Flashix
because we model code at a lower level of abstraction, so even issues like
concurrency and memory safety show up in each interface. We were inspired to
develop the DaisyNFS design to get truly sequential reasoning by the pain in
verifying GoTxn, and found modularity and clean abstractions much easier once
code ran within a transaction.

Where it lacks in generality, Flashix does make up for in verifying a taller
storage stack than DaisyNFS. Flash storage has a more limited API than a
standard drive --- in particular flash blocks must be completely erased before
being reused. A flash file system works around this limitation with \emph{garbage
collection}, where occasionally the system identifies a mostly-unused block,
moves its valid data elsewhere, and then erases it to reclaim space. This is
implemented by maintaining a logical-to-physical block mapping, similar to
virtual memory. DaisyNFS does not require any of this code. We do generally run
on SSDs which internally use flash blocks and themselves implement garbage
collection and a logical block mapping so that they can support overwriting data
in-place.

\section{Crash-safety foundations}

There are a variety of foundational tools for reasoning about crash safety,
largely for sequential systems.

FSCQ~\cite{chen:fscq,chen:dfscq,hchen-phd} is a verified sequential file
system that features Crash Hoare Logic (CHL). CHL extends the basic Hoare triple
with a \emph{crash condition} that holds at all intermediate points in the
function's execution. Crash conditions handle a core difficulty of crashes,
namely that they stop the system at some intermediate step. There are two
remaining challenges: a crash wipes in-memory state, and the system might crash again
while recovering after a crash. CHL connects the system's crash conditions to a
specification for recovery to handle these two issues. A crash predicate
transformation captures what can be assumed when recovery starts, and for
crashes during recovery CHL requires that recovery be \emph{idempotent} in the
sense that its crash condition implies its own precondition. CHL was used to
specify and verify FSCQ~\cite{chen:fscq} and a more performant successor
DFSCQ~\cite{chen:dfscq}.

Yggdrasil~\cite{sigurbjarnarson:yggdrasil} takes a different approach to crash
safety. The basic definition is \emph{crash refinement}, which says that a
system implements an interface correctly, including a specification for what a
crash followed by recovery is allowed to do. Note that unlike CHL this
specification is about a collection of methods implementing an abstract,
specification transition system, not about individual methods. Yggdrasil uses
crash refinement to specify and verify a file system comparable to the file
system in xv6, a teaching operating system. The implementation uses Z3 to check
crash refinement, which the authors show is able to handle a system of this
complexity by breaking down the implementation into small enough layers.

Argosy~\cite{chajed:argosy}, which I led the development of but is not part of
this thesis, combines aspects of FSCQ and Yggdrasil. The key new idea is to
develop the metatheory for \emph{recovery refinement} that shows how systems
compose when both have recovery procedures --- what is non-trivial to handle is
that a crash in the composed recovery procedure requires starting over from the
beginning. Recovery refinement can be viewed as an extension of crash refinement
with verified metatheory for recovery, largely left implicit in the Yggdrasil
paper. Argosy also shows how to encode the conditions of recovery refinement
using CHL so that a single layer is verified using the CHL program logic.

VeriBetrKV~\cite{hance:veribetrkv} takes yet another approach to reasoning about
crashes, this time friendly to encoding in Dafny, a sequential verification
system with integrated support for programming and verification. The main idea
related to crash safety is to adopt the style from
IronFleet~\cite{hawblitzel:ironfleet} and think of a storage system as a
distributed system made up of the CPU and the storage device. The extension
needed for crash reasoning is to add a crash transition to the storage device
that non-deterministically wipes any buffered but unacknowledged writes, and
then to show that when this happens it corresponds to an appropriate
application-level transition modeling crashes (similar to the crash refinement
definition from Yggdrasil and recovery refinement in Argosy, although this is
associated with a code transition rather than a dedicated recovery procedure).
VeriBetrKV is used to verify a persistent key-value store.

Perennial has crash conditions that look similar to CHL's crash conditions,
albeit as part of a concurrent program logic rather than a sequential one. We do
carry out a refinement proof in the style of Argosy, which is similar to the
specification style in VeriBetrKV and Yggdrasil, but because it is connected to
concurrent reasoning the proof techniques are more sophisticated.

\section{Concurrency foundations}

There are a number of approaches proposed to verifying concurrent programs. It
would be hard to do justice to the historical development of concurrency
reasoning. Looking at approaches that are actively used in research and
connected to executable implementation, two broad strategies are commonly used:
developing concurrent \emph{program logics}, and using \emph{refinement}-based
techniques.

Many refinement-based techniques are based on the idea of \emph{reduction},
which appeared originally in Lipton's theory of ``movers''~\cite{lipton:movers}.
The idea behind reduction is to reason about a program through program
transformations that show the program is equivalent to a simpler program. These
techniques can reason about concurrency by showing that a concurrent program is
equivalent to a program with sequential or atomic regions. These ideas have been
used as part of the CIVL verifier~\cite{hawblitzel:civl,kragl:civl-layers} and
Armada~\cite{lorch:armada}; my own prior work on CSPEC~\cite{chajed:cspec} was
also based on movers, before working on Perennial. Reduction-based techniques
generally reason about a program through a series of transformations, each
making the program slightly simpler, keeping the proof of each transformation's
correctness more manageable.

One large verified system, CertiKOS, is based on a custom verification
infrastructure called Certified Concurrent Abstraction
Layers~\cite{gu:certikos-ccal} which based on refinement but not reduction. This
work is notable for verifying a system (a simple operating system) not just at
an abstract protocol level but all the way down to concurrent code. The proof
composes with the CompCert compiler correctness theorem to carry the guarantees
down to the assembly code of the operating system.

Program logics are an alternative approach based on giving specifications to
each function in the program, within a logic that has useful rules for proving
and composing specifications. Hoare logic is a classic program
logic for sequential programs that based on pre- and post-conditions.
Concurrency makes it harder to construct a logic that can usefully reason about
many concurrency patterns (completeness) while also giving specifications that
hold in the presence of concurrent threads (soundness). One productive line of
work has been based on concurrent separation logic (CSL)~\cite{brookes:csl}.

The Verified Software Toolchain is notable for connecting a CSL-based logic
(VST-Floyd) down to proofs of C code, including a connection to CompCert to
carry these guarantees down to assembly~\cite{cao:vst-floyd}. It has been used
for a number of sequential verified C programs and recently to some shared
memory C libraries.

Perennial builds directly on Iris~\cite{jung:iris-jfp}. Iris is a general
framework for concurrency, featuring a base logic with key features for
concurrency (step indexing and separation-logic resources, including
\emph{higher-order} resources used to define invariants for example) and a
program logic built on the base logic. This decomposition was valuable for
Perennial because we made two core changes to Iris: first, the program logic
itself is extended with crash safety reasoning, and second, the framework is
applied to our GooseLang models of Go code. In both cases the generality of Iris
was valuable, as the framework is not tied to reasoning about a particular
programming language or even to its usual program logic. Prior to this work,
Iris had not typically been used for reasoning about executable code (though
projects like RefinedC~\cite{sammler:refinedc} and our own work on Goose are
changing that).

\section{Other stuff}

persistent memory semantics

ext4 semantics from Azalea's group

\section{Related to GoTxn}

comparison of system to jbd2

Push/Pull model

DFSCQ logging system. ARIES and its FTCSL proof

\input{go-journal/02-related}

\section{Related to DaisyNFS}

some similarities to design of Yggdrasil

indirect block verification-friendly design from DFSCQ

The Dafny side of DaisyNFS is a new implementation but its design and aspects of
the proof strategy were inspired by other verified file systems like
DFSCQ~\cite{chen:dfscq} (especially its indirect block implementation described
in Konradi's master's thesis~\cite{akonradi-meng}) and
Yggdrasil~\cite{sigurbjarnarson:yggdrasil}.

AtomFS does concurrency reasoning

\input{daisy-nfs/02-related}
