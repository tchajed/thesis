% subsection of GoTxn proof section
\subsection{Proving program refinement}
\label{sec:txn:refinement}

\newcommand{\txnmapsto}{\mapsto_{\cc{txn}}}
\newcommand{\thdmapsto}{\Rightarrow}

Recall that \cref{thm:gotxn-program-refinement} is the overall correctness
theorem for GoTxn. It says that the GoTxn implementation is a \emph{program
refinement} between the Txn layer (with programs that use transactions) and the
Disk layer (with an implementation that interacts with a disk).
That is, given a program
$p : \gooselayer{Txn}$, if the transaction operations of $p$ are linked with
GoTxn (implemented in $\gooselayer{Disk}$), the implementation program's
observable behaviors (from running on a disk) are a subset of the
specification's behaviors (with high-level transaction-system operations, and in
particular atomicity for transactions). The proof of this theorem leverages the
journaling specification from \cref{sec:txn:lifting}, extending it to also
reason about the concurrency control implemented with two-phase locking.

In general, the Perennial framework supports proving refinements between a
specification layer $\gooselayer{S}$ and an implementation layer $\gooselayer{I}$ by constructing
a simulation between the specification and its implementation. The simulation is
expressed in terms of refinement conditions that are written using the usual
Perennial Hoare triples specifications (with pre- and postconditions),
so that they can be proven using the full spectrum of techniques in Perennial.

Following an
approach developed by \citet{turon:caresl}, in a refinement proof in Perennial the execution of the specification
program is represented by \emph{ghost state}. The logic then has assertions for
describing this ghost state.  For example, for the Txn layer, the assertion $\cc{a}
\txnmapsto b$ says that address $a$ contains the value $b$ in the ghost
transaction system's state. In addition, there are \emph{thread points-to}
assertions, written $j \thdmapsto \cc{e}$, which says that thread $j$ in the
specification program is executing program $\cc{e}$. Perennial has rules
for updating the ghost state by ``executing'' these ghost threads, such as the
following view shift:
\[
  (\cc{a} \txnmapsto b) \sep (j \thdmapsto \cc{Write(a, b')}) \vs
  \cc{a} \txnmapsto b'
\]
which updates the value stored at $\cc{a}$ as a result of a write.

To establish the refinement, the proof engineer first defines a
\emph{representation invariant} $I$, an assertion in the logic that describes a
relation between the specification state and the implementation state.
Perennial's proof rules ensure that this designated invariant must hold before
and after each step of a program throughout the proof. Next, the proof engineer
proves a Hoare triple for each operation $o$ of $\gooselayer{S}$ and its
corresponding implementation $p_o$ in $\gooselayer{I}$:
\[
\hoare{(j \thdmapsto o) * \knowInv{}{I}}{p_o}{\Ret{v} (j \thdmapsto v)}
 \]
Such a \emph{refinement triple} says that if a specification thread is executing
$o$ and an implementation thread is running $p_o$, then the representation
invariant $I$ is maintained and the value $v$ returned by running $p_o$ is a valid
return value of operation $o$. In the proof of this triple, the ghost execution
rule above is used at the linearization point of $p_o$, to mark
when the operation logically takes effect by executing $o$ in the ghost code.

These refinement triples imply a refinement between programs in $\gooselayer{S}$
and $\gooselayer{I}$. This is formally stated and proven in Coq, using the Perennial
framework's soundness theorem.

In the particular case of the transaction system, the key refinement triple to
prove is for a block of code $f$ enclosed in transaction \cc{Begin} and
\cc{Commit} operations; for example the triple might look the following (for a
particular transaction $f$ that copies from address 0 to 1):
\[
  \hoareV{ \left( j \thdmapsto %
      \atomically{v \gets \mathit{Read}(0);\, \mathit{Write}(1, v)} %
    \right) %
    \sep \knowInv{}{I}}%
  {\begin{aligned}
&\cc{tx := Begin();} \\
&\cc{v := tx.Read(0); tx.Write(1, v);} \\
&\cc{tx.Commit()}
\end{aligned}}%
    {j \thdmapsto ()}
\]
The difficulty in proving this triple is that the linearization point is at the
very end when the code calls \cc{Commit}, at which point the actual earlier
execution of $f$ becomes visible to other threads. The proof must show that
ghost-executing the specification's \cc{atomically} block at this point is valid by
tracking the behavior of $f$.

To show this, our proof maintains a stronger invariant during a transaction's
execution. As the transaction executes, we track the initial, on-disk value of any
objects accessed in a map $J$. The domain of this map
$\Sigma = \operatorname{dom}(J)$ is the \emph{footprint} of the transaction,
which two-phase locking keeps locked during the transaction. The intuition
behind the invariant is that if the transaction only depends on $J$, the
transaction's execution can be delayed to take place atomically at the call to
\cc{Commit} and its behavior will be the same since the subset of the journal
$J$ is the same.

The proof needs to reason about the two-phase locking concurrency control in
order to use the journaling layer's lifting specification as part of this proof.
Perennial has a crash-aware specification for locks, described in
\cref{sec:perennial:wpc}, that allows us to reason about the per-address locks
while also reasoning about crashes in the middle of a transaction. To use this
specification, the proof defines a per-address lock invariant and crash
invariant --- the lock invariant is a property that holds when the lock is
acquired (and must be shown when it is released), while the crash invariant is a
guarantee that also holds on crash. In the case of the two-phase locking code,
both the lock and crash invariants for the lock associated with address $a$
contain ownership of $\exists o, a \mapstoDisk o$, which gives the transaction
the ability to lift address $a$ and read and write it with the journaling
system's interface. The invariant has additional constraints to assert that the
value $o$ is the same as the one in the transactional disk.

More formally, the proof constructs a second simulation relation during the
execution of a transaction $\cc{f}$.  Let $J$ be a map giving the values of each
object in the transaction's footprint $\Sigma$ at the first time they are
accessed by $\cc{f}$, and let $J'$ be a mapping giving the transaction's current
buffered in-memory view of the same addresses.  Then, the invariant requires
that after $n$ steps of execution:
%
\begin{enumerate}

\item The transaction holds the lock for every address $a \in \Sigma$. The
transaction has ownership over $\bigast_{(a,o) \in J} a \mapstoLftd o$ and
$\bigast_{(a,o') \in J'} a \mapstoOp o'$. These come from lifting the
$a \mapstoDisk o$ assertion from each lock invariant, and then writing to update
the operation-local points-to assertion.

\item Executing $n$ steps of $\cc{f}$ in \emph{any} starting state that has the same
  values as $J$ for the addresses in $\Sigma$ can lead to a state with values given
  by $J'$.

\end{enumerate}
%
When the transaction is about to commit, the locking described by the first part of the
invariant ensures that the durable value of each address still match the values
in $J$. The second part of the invariant means that even though other
parts of the state outside of $\Sigma$ may have changed, those changes do not
affect execution of $\cc{f}$. Thus, the ghost execution of $\cc{f}$ at this point will
have the same behavior as the implementation. The transaction's invariant
maintains ownership of the resources to use the journal's \cc{Commit}
specification. The postcondition and crash condition of that specification
return new disk points-to assertions consistent with either $J$ or $J'$ as
appropriate. If the commit is successful, then the second part of the
transaction system's invariant allows issuing a ghost-execution update to change
the transactional disk from $J$ to $J'$ (for the subset $\Sigma$), and it
guarantees that this correctly simulates \cc{f}.

Showing that the second part of the invariant holds requires that code within a
transaction must not access global state outside of the
transaction system, as mentioned in \cref{sec:txn:safe}. Accesses to such global state
would violate the invariant because their behavior would then depend upon
things outside of the footprint $\Sigma$. Because those global values could change
by the time the transaction commits, the above argument would no longer work if they were allowed.

The allocator creates another subtlety related to the second part of this
invariant. Allocations do not hold the allocator lock throughout the remainder
of a transaction. This seems to violate the two-phase locking pattern, since
allocations could be implicitly observed by other concurrent transactions from
the fact that an allocated address is no longer free. As described in
\cref{sec:txn:safe}, GoTxn under-specifies the allocator's behavior so that it
atomically follows its (non-deterministic) specification even though it is not
protected by the 2PL locking discipline. Correspondingly, in the
proof, the footprint $J$ of a transaction does not describe the allocator state
and at the ghost-execution linearization point the addresses returned by the
allocator may no longer be free.

% Suppose the transaction being simulated is $\operatorname{Atomically}{f}$, and the implementation
% has executed $n$ steps of $f$, accessing addresses in the set $\sigma$.

% Let $J_1 : \cc{addr} \rightarrow Obj$ be a map giving the durable state of the journal at the start of the transaction, and let $J_2$ be the current buffered in-memory view of the state from the perspective of the transaction.
% Then, the invariant requires that:
% \begin{enumerate}
% \item the transaction holds the lock for every address $a \in \sigma$
% \item for each $a$, $J_1(a)$ matches the ghost state value for the address $a$
% \item if $J_1'$ is a mapping such that $\forall a \in \sigma$, $J_1(a) = J_1'(a)$, then executing $f$ for $n$ steps with an initial journal $J_1'$
% \end{enumearte}
% \joe{this would probably be vastly improved by using math notation that matches whatever will have been used in the previous two sections}
